{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewFaiello/UW_ISEA/blob/main/Gradient_Descent_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A step-by-step walkthrough of gradient descent with OLS\n",
        "\n",
        "In this colab, you will learn to use gradient descent to calculate the slope and intercept of a line.\n"
      ],
      "metadata": {
        "id": "iWbI71qfpgCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will set up some data and plot it. We will also calculate the OLS coefficients using a pre-built function"
      ],
      "metadata": {
        "id": "SV2A2qbmp0Kf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XFRQXBDeQB-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ecc379-6dd7-488c-aa97-0bb76a335bd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x785049473ec0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "n_observations = 100\n",
        "\n",
        "x = np.random.rand(n_observations) * 10  # Values between 0 and 10\n",
        "\n",
        "# Define the true relationship (linear with some noise)\n",
        "true_slope = 2\n",
        "true_intercept = 1\n",
        "noise_level = 1\n",
        "\n",
        "# Generate y values based on the true relationship and add some noise\n",
        "y = true_slope * x + true_intercept + np.random.normal(0, noise_level, n_observations)\n",
        "\n",
        "# Estimate model using OLS\n",
        "X_ols = sm.add_constant(x)  # Add intercept term\n",
        "model = sm.OLS(y, X_ols).fit()\n",
        "estimated_intercept, estimated_slope = model.params\n",
        "y_estimated = estimated_slope * x + estimated_intercept\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "y_pred = estimated_slope * x + estimated_intercept\n",
        "mse = np.mean((y - y_pred) ** 2)\n",
        "\n",
        "\n",
        "# Create a plot\n",
        "plt.scatter(x, y, color='blue', marker='o', edgecolors='black')\n",
        "plt.plot(x, y_estimated, color='green', linestyle='--', linewidth=2, label=\"OLS\")\n",
        "\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.title(\"Sample Scatter Plot\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "print(f\"True Intercept: {true_intercept}, True Slope: {true_slope}\")\n",
        "print(f\"Estimated Intercept: {estimated_intercept:.4f}, Estimated Slope: {estimated_slope:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Questions:\n",
        "- Why isn't the estimated intercept 1?\n",
        "- Why isn't the estimated slope 2?\n",
        "- The MSE is 0.8, do we expect MSE to ever be 0 (with real data)?"
      ],
      "metadata": {
        "id": "HyqGxXalqABz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Univariate OLS, the gradient way\n",
        "\n",
        "In this implementation, we will **not** use linear algebra or a pre-canned function to solve OLS. Instead we will use gradient descent!\n",
        "\n",
        "\n",
        "A simple linear model is:  \n",
        "\n",
        "$$\n",
        "y = m \\mathbf{X} + b\n",
        "$$\n",
        "\n",
        "We want to identify $m, b$ given $X, y$\n",
        "\n",
        "1. Define a cost function - for OLS we will use half Mean Squared Error (MSE) $$\n",
        "C(m, b) = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - (\\hat{m} x_i + \\hat{b}))^2\n",
        "$$\n",
        "1. Set initial, arbitrary values for $m, b$ (lets use 0,0)\n",
        "1. Predict $y$. $$\n",
        "\\hat{y} = m x + b\n",
        "$$\n",
        "1. Compute the gradient: find the partial derivative of the cost function for m and b.\n",
        "  - $$\n",
        "\\frac{\\partial C}{\\partial m} = \\frac{1}{n} \\sum_{i=1}^{n} x_i (y_i - \\hat{y}_i) $$\n",
        "  - $$\n",
        "\\frac{\\partial C}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)\n",
        "$$\n",
        "\n",
        "1. Update $m, b$ using the gradient and a learning rate\n",
        "1. Repeat 3 to 5\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zIHCu1nTSjBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group Work\n",
        "- Note: Use the top menu `Runtime > Restart Session` to reset your cells if things start getting weird\n",
        "- I reccomend having one person share their screen as you work through this"
      ],
      "metadata": {
        "id": "dEs8iLMWviG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Questions\n",
        "- Explain the cost function in your own words $$ C(m, b) = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - (\\hat{m} x_i + \\hat{b}))^2\n",
        "$$\n",
        "- Explain what a partial derivative is"
      ],
      "metadata": {
        "id": "-sg79iq-uTuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the cost function (Mean Squared Error)\n",
        "def compute_cost(m, b, x, y):\n",
        "    n = len(x)\n",
        "    total = 0.0\n",
        "\n",
        "    for i in range(n):\n",
        "        y_hat = m * x[i] + b\n",
        "        error = y[i] - y_hat\n",
        "        total += error ** 2\n",
        "\n",
        "    cost = total / (2 * n)\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "6FrGSg2pSiW3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2, 3: Set initial 0 values for m and b, and predict y\n",
        "m = 0  # Initial slope\n",
        "b = 0  # Initial intercept\n",
        "\n",
        "def predict(m, b, x):\n",
        "    y_pred = []\n",
        "    for xi in x:\n",
        "        y_pred.append(m * xi + b)\n",
        "    return y_pred\n",
        "\n",
        "y_pred = predict(m, b, x)\n",
        "\n",
        "print(y[0:4]) # print the first 4 values as a check\n",
        "print(y_pred[0:4])\n",
        "print(compute_cost(m, b, x, y))"
      ],
      "metadata": {
        "id": "2TM2aoYEYrFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b340154-f400-4875-bd0e-03f483817076"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 8.57784945 19.71527878 15.73163961 10.98560077]\n",
            "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
            "71.23624476139783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick check, you should be printing all 0's for y_pred above. Why?"
      ],
      "metadata": {
        "id": "cVUpALLMv0T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 4, 5: Compute the gradient, update m and b\n",
        "def compute_gradients(x, y, y_pred):\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    n = len(x)\n",
        "    errors = y - y_pred  # (y_i - yhat_i)\n",
        "\n",
        "    dm = -(1 / n) * np.sum(x * errors)\n",
        "    db = -(1 / n) * np.sum(errors)\n",
        "\n",
        "    return dm, db  # Gradient w.r.t. m, b\n",
        "\n",
        "def update_parameters(m, b, dm, db, learning_rate=0.01):\n",
        "    m = m - learning_rate * dm\n",
        "    b = b - learning_rate * db\n",
        "    return m, b\n",
        "\n",
        "dm, db = compute_gradients(x, y, y_pred)\n",
        "print(f\"m-gradient = {dm:.1f}, b-gradient = {db:.1f}\")\n",
        "\n",
        "m, b = update_parameters(m, b, dm, db)\n",
        "print(f\"New m = {m:.2f}, New b = {b:.2f}\")\n",
        "print(f\"Cost = {compute_cost(m, b, x, y)}\")"
      ],
      "metadata": {
        "id": "orxcOzJ8ZDca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acab481-7d0c-49c1-bc7b-99587ac552d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m-gradient = -66.0, b-gradient = -10.4\n",
            "New m = 5.94, New b = 0.94\n",
            "Cost = 240.77369708325338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the output above, what would happen if we didn't use a learning rate? Did cost go up or down?"
      ],
      "metadata": {
        "id": "MgS1p9cAwXQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Put it together\n",
        "Create a loop to repeat steps 3-5, run it three times print m, b and cost for each step"
      ],
      "metadata": {
        "id": "n4Sb0MbckjfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "HLTSxLlBa11r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# --- helpers (from earlier steps) ---\n",
        "def predict(m, b, x):\n",
        "    x = np.array(x)\n",
        "    return m * x + b\n",
        "\n",
        "def compute_cost(m, b, x, y):\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    n = len(x)\n",
        "    y_pred = m * x + b\n",
        "    cost = np.sum((y - y_pred) ** 2) / (2 * n)\n",
        "    return cost\n",
        "\n",
        "def compute_gradients(x, y, y_pred):\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    n = len(x)\n",
        "    errors = y - y_pred\n",
        "\n",
        "    dm = -(1 / n) * np.sum(x * errors)\n",
        "    db = -(1 / n) * np.sum(errors)\n",
        "    return dm, db\n",
        "\n",
        "def update_parameters(m, b, dm, db, learning_rate=0.01):\n",
        "    m = m - learning_rate * dm\n",
        "    b = b - learning_rate * db\n",
        "    return m, b\n",
        "\n",
        "# --- Step: initialize ---\n",
        "m, b = 0.0, 0.0\n",
        "learning_rate = 0.01\n",
        "\n",
        "# --- Run it 3 times and print each step ---\n",
        "for step in range(1, 10):\n",
        "    y_pred = predict(m, b, x)\n",
        "    dm, db = compute_gradients(x, y, y_pred)\n",
        "    m, b = update_parameters(m, b, dm, db, learning_rate)\n",
        "    cost = compute_cost(m, b, x, y)\n",
        "    print(f\"Step {step}: m = {m:.4f}, b = {b:.4f}, cost = {cost:.4f}\")\n",
        "\n",
        "# --- Now run it 1000 times; only print final values ---\n",
        "m, b = 0.0, 0.0  # reset (optional, but usually desired)\n",
        "\n",
        "for _ in range(1000):\n",
        "    y_pred = predict(m, b, x)\n",
        "    dm, db = compute_gradients(x, y, y_pred)\n",
        "    m, b = update_parameters(m, b, dm, db, learning_rate)\n",
        "\n",
        "print(f\"m = {m:.2f}, b = {b:.2f}, cost = {compute_cost(m, b, x, y):.2f}\")\n"
      ],
      "metadata": {
        "id": "6j5k7pzwb8DI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507d9a66-d5d7-4ff3-a797-3e5fadb0f065"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: m = 0.6603, b = 0.1040, cost = 33.6112\n",
            "Step 2: m = 1.1119, b = 0.1760, cost = 16.0032\n",
            "Step 3: m = 1.4207, b = 0.2260, cost = 7.7627\n",
            "Step 4: m = 1.6318, b = 0.2609, cost = 3.9060\n",
            "Step 5: m = 1.7762, b = 0.2856, cost = 2.1009\n",
            "Step 6: m = 1.8748, b = 0.3033, cost = 1.2558\n",
            "Step 7: m = 1.9421, b = 0.3161, cost = 0.8600\n",
            "Step 8: m = 1.9881, b = 0.3257, cost = 0.6744\n",
            "Step 9: m = 2.0194, b = 0.3330, cost = 0.5873\n",
            "m = 1.96, b = 1.16, cost = 0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some possible stopping rules for this loop?\n",
        "Designate one person from your group to talk through your solution"
      ],
      "metadata": {
        "id": "wWdopUOAojcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework Collaboration\n",
        "\n",
        "Your homework for next week includes a model building exercise. I encourage you to talk in your group now about potential times you can connect to collaborate"
      ],
      "metadata": {
        "id": "8s81XyzFrBg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finished early?\n",
        "\n",
        "Discuss with your group applied education ML cases you are familiar with"
      ],
      "metadata": {
        "id": "MM68ft_rmqrt"
      }
    }
  ]
}